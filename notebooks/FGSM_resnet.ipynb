{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.nets import inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim\n",
    "tf.flags.DEFINE_string(\n",
    "    'master', '', 'The address of the TensorFlow master to use.')\n",
    "tf.flags.DEFINE_string(\n",
    "    'checkpoint_path', 'nips-2017-adversarial-learning-development-set/inception_v3.ckpt', 'Path to checkpoint for inception network.')\n",
    "tf.flags.DEFINE_string(\n",
    "    'input_dir', 'nips-2017-adversarial-learning-development-set/images/', 'Input directory with images.')\n",
    "tf.flags.DEFINE_string(\n",
    "    'output_dir', '', 'Output directory with images.')\n",
    "tf.flags.DEFINE_float(\n",
    "    'max_epsilon', 4.0, 'Maximum size of adversarial perturbation.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'image_width', 299, 'Width of each input images.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'image_height', 299, 'Height of each input images.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'batch_size', 16, 'How many images process at one time.')\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images(input_dir, batch_shape):\n",
    "    images = np.zeros(batch_shape)\n",
    "    filenames = []\n",
    "    idx = 0\n",
    "    batch_size = batch_shape[0]\n",
    "    # Limit to first 20 images for this example\n",
    "    for filepath in sorted(tf.gfile.Glob(os.path.join(input_dir, '*.png')))[:20]:\n",
    "        with tf.gfile.Open(filepath, \"rb\") as f:\n",
    "            images[idx, :, :, :] = imread(f, mode='RGB').astype(np.float)*2.0/255.0 - 1.0\n",
    "        filenames.append(os.path.basename(filepath))\n",
    "        idx += 1\n",
    "        if idx == batch_size:\n",
    "            yield filenames, images\n",
    "            filenames = []\n",
    "            images = np.zeros(batch_shape)\n",
    "            idx = 0\n",
    "    if idx > 0:\n",
    "        yield filenames, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_images(images, filenames, output_dir):\n",
    "    for i, filename in enumerate(filenames):\n",
    "        with tf.gfile.Open(os.path.join(output_dir, filename), 'w') as f:\n",
    "            img = (((images[i, :, :, :] + 1.0) * 0.5) * 255.0).astype(np.uint8)\n",
    "            Image.fromarray(img).save(f, format='PNG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InceptionModel(object):\n",
    "  \"\"\"Model class for CleverHans library.\"\"\"\n",
    "\n",
    "  def __init__(self, num_classes):\n",
    "    self.num_classes = num_classes\n",
    "    self.built = False\n",
    "\n",
    "  def __call__(self, x_input):\n",
    "    \"\"\"Constructs model and return probabilities for given input.\"\"\"\n",
    "    reuse = True if self.built else None\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "      _, end_points = inception.inception_v3(\n",
    "          x_input, num_classes=self.num_classes, is_training=False,\n",
    "          reuse=reuse)\n",
    "    self.built = True\n",
    "    output = end_points['Predictions']\n",
    "    # Strip off the extra reshape op at the output\n",
    "    probs = output.op.inputs[0]\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 2.0 * 16.0 / 255.0\n",
    "batch_shape = [FLAGS.batch_size, FLAGS.image_height, FLAGS.image_width, 3]\n",
    "num_classes = 1001\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels = pd.read_csv(\"nips-2017-adversarial-learning-development-set/images.csv\")\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from nips-2017-adversarial-learning-development-set/inception_v3.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "    model= InceptionModel(num_classes)\n",
    "\n",
    "    fgsm = FastGradientMethod(model)\n",
    "    x_adv = fgsm.generate(x_input, eps=eps, clip_min=-1., clip_max=1.)\n",
    "\n",
    "    saver = tf.train.Saver(slim.get_model_variables())\n",
    "    session_creator = tf.train.ChiefSessionCreator(\n",
    "        scaffold=tf.train.Scaffold(saver=saver),\n",
    "        checkpoint_filename_with_path=FLAGS.checkpoint_path,\n",
    "        master=FLAGS.master)\n",
    "\n",
    "    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "        for filenames, images in load_images(\"nips-2017-adversarial-learning-development-set/images/\", batch_shape):\n",
    "            adv_images = sess.run(x_adv, feed_dict={x_input: images})\n",
    "            save_images(adv_images, filenames, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imread('nips-2017-adversarial-learning-development-set/images/0aebe24fc257286e.png',mode='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = pd.read_csv(\"nips-2017-adversarial-learning-development-set/categories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from nips-2017-adversarial-learning-development-set/inception_v3.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    x_input = tf.placeholder(tf.float32, shape=batch_shape)\n",
    "\n",
    "    with slim.arg_scope(inception.inception_v3_arg_scope()):\n",
    "        _, end_points = inception.inception_v3(x_input, num_classes=num_classes, is_training=False)\n",
    "    \n",
    "    predicted_labels = tf.argmax(end_points['Predictions'], 1)\n",
    "\n",
    "    saver = tf.train.Saver(slim.get_model_variables())\n",
    "    session_creator = tf.train.ChiefSessionCreator(\n",
    "                      scaffold=tf.train.Scaffold(saver=saver),\n",
    "                      checkpoint_filename_with_path=FLAGS.checkpoint_path,\n",
    "                      master=FLAGS.master)\n",
    "\n",
    "    with tf.train.MonitoredSession(session_creator=session_creator) as sess:\n",
    "        predicted_classes = sess.run(predicted_labels, feed_dict={x_input: images})\n",
    "        predicted_nontargeted_classes = sess.run(predicted_labels, feed_dict={x_input: adv_images})\n",
    "        #predicted_targeted_classes = sess.run(predicted_labels, feed_dict={x_input: targeted_images})\n",
    "\n",
    "predicted_classes_names = (pd.DataFrame({\"CategoryId\": predicted_classes})\n",
    "                           .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())\n",
    "\n",
    "predicted_nontargeted_classes_names = (pd.DataFrame({\"CategoryId\": predicted_nontargeted_classes})\n",
    "                          .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())\n",
    "\n",
    "#predicted_targeted_classes_names = (pd.DataFrame({\"CategoryId\": predicted_targeted_classes})\n",
    "#                          .merge(categories, on=\"CategoryId\")[\"CategoryName\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['monastery',\n",
       " 'espresso',\n",
       " 'barn',\n",
       " 'military uniform',\n",
       " 'nematode, nematode worm, roundworm',\n",
       " 'nematode, nematode worm, roundworm',\n",
       " 'nematode, nematode worm, roundworm',\n",
       " 'nematode, nematode worm, roundworm',\n",
       " 'nematode, nematode worm, roundworm',\n",
       " 'nematode, nematode worm, roundworm',\n",
       " 'nematode, nematode worm, roundworm',\n",
       " 'nematode, nematode worm, roundworm',\n",
       " 'nematode, nematode worm, roundworm',\n",
       " 'nematode, nematode worm, roundworm',\n",
       " 'nematode, nematode worm, roundworm',\n",
       " 'nematode, nematode worm, roundworm']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['palace',\n",
       " 'teapot',\n",
       " 'barn',\n",
       " 'brassiere, bra, bandeau',\n",
       " 'prayer rug, prayer mat',\n",
       " 'prayer rug, prayer mat',\n",
       " 'prayer rug, prayer mat',\n",
       " 'prayer rug, prayer mat',\n",
       " 'prayer rug, prayer mat',\n",
       " 'prayer rug, prayer mat',\n",
       " 'prayer rug, prayer mat',\n",
       " 'prayer rug, prayer mat',\n",
       " 'prayer rug, prayer mat',\n",
       " 'prayer rug, prayer mat',\n",
       " 'prayer rug, prayer mat',\n",
       " 'prayer rug, prayer mat']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_nontargeted_classes_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
