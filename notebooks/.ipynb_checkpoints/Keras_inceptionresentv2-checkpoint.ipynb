{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PIL\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from random import randrange\n",
    "%matplotlib inline\n",
    "from tensorflow.contrib.slim.nets import inception\n",
    "import keras\n",
    "from keras import __version__\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim\n",
    "tf.flags.DEFINE_string(\n",
    "    'master', '', 'The address of the TensorFlow master to use.')\n",
    "tf.flags.DEFINE_string(\n",
    "    'checkpoint_path', 'nips-2017-adversarial-learning-development-set/inception_v3.ckpt', 'Path to checkpoint for inception network.')\n",
    "tf.flags.DEFINE_string(\n",
    "    'input_dir', 'nips-2017-adversarial-learning-development-set/images/', 'Input directory with images.')\n",
    "tf.flags.DEFINE_string(\n",
    "    'output_dir', '', 'Output directory with images.')\n",
    "tf.flags.DEFINE_float(\n",
    "    'max_epsilon', 4.0, 'Maximum size of adversarial perturbation.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'image_width', 299, 'Width of each input images.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'image_height', 299, 'Height of each input images.')\n",
    "tf.flags.DEFINE_integer(\n",
    "    'batch_size', 16, 'How many images process at one time.')\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noisy(noise_typ,image):\n",
    "    #Gaussian\n",
    "   if noise_typ == 1:\n",
    "      row,col,ch= image.shape\n",
    "      mean = 0\n",
    "      var = 0.1\n",
    "      sigma = var**0.5\n",
    "      gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "      gauss = gauss.reshape(row,col,ch)\n",
    "      noisy = image + gauss\n",
    "      return noisy.astype('uint8')\n",
    "    #Salt and Pepper\n",
    "   elif noise_typ == 2:\n",
    "      row,col,ch = image.shape\n",
    "      s_vs_p = 0.5\n",
    "      amount = 0.004\n",
    "      out = np.copy(image)\n",
    "      # Salt mode\n",
    "      num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "      coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape]\n",
    "      out[coords] = 1\n",
    "      # Pepper mode\n",
    "      num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "      coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "              for i in image.shape]\n",
    "      out[coords] = 0\n",
    "      return out\n",
    "    #Poisson\n",
    "   elif noise_typ == 3:\n",
    "      vals = len(np.unique(image))\n",
    "      vals = 2 ** np.ceil(np.log2(vals))\n",
    "      noisy = np.random.poisson(image * vals) / float(vals)\n",
    "      return noisy\n",
    "    #speckle\n",
    "   elif noise_typ ==4:\n",
    "      row,col,ch = image.shape\n",
    "      gauss = np.random.randn(row,col,ch)\n",
    "      gauss = gauss.reshape(row,col,ch)        \n",
    "      noisy = image + image * gauss\n",
    "      return noisy.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subsample(training_images,training_labels, ratio=0.8):\n",
    "    shuffle_index = np.random.permutation(len(training_labels))\n",
    "    training_images = training_images[shuffle_index]\n",
    "    training_labels = training_labels[shuffle_index]\n",
    "    sample = list()\n",
    "    sample_labels = list()\n",
    "    n_sample = round(training_images.shape[0] * ratio)\n",
    "    while len(sample) < n_sample:\n",
    "        index = randrange(training_images.shape[0])\n",
    "        sample.append(training_images[index,:,:,:])\n",
    "        sample_labels.append(training_labels[index])\n",
    "    return np.asarray(sample),np.asarray(sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_training_images(training_image_dir):\n",
    "\n",
    "    image_index = 0\n",
    "    \n",
    "    images = np.ndarray(shape=(500*200, 64,64,3))\n",
    "    names = []\n",
    "    labels = []                       \n",
    "    \n",
    "    # Loop through all the types directories\n",
    "    for type in os.listdir(training_image_dir):\n",
    "        if os.path.isdir(training_image_dir + type + '/images/'):\n",
    "            type_images = os.listdir(training_image_dir + type + '/images/')\n",
    "            # Loop through all the images of a type directory\n",
    "            #batch_index = 0;\n",
    "            #print (\"Loading Class \", type)\n",
    "            for image in type_images:\n",
    "                image_file = os.path.join(training_image_dir, type + '/images/', image)\n",
    "\n",
    "                # reading the images as they are; no normalization, no color editing\n",
    "                image_data = mpimg.imread(image_file) \n",
    "                #print ('Loaded Image', image_file, image_data.shape)\n",
    "                if (image_data.shape == (64, 64, 3)):\n",
    "                    images[image_index, :,:,:] = image_data\n",
    "                    \n",
    "                    labels.append(type)\n",
    "                    names.append(image)\n",
    "                    \n",
    "                    image_index += 1\n",
    "                    #batch_index += 1\n",
    "                #if (batch_index >= batch_size):\n",
    "                 #   break;\n",
    "    labels = np.asarray(labels)\n",
    "    names = np.asarray(names)\n",
    "    return (images[0:len(labels)].astype('uint8'), labels, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale(img):\n",
    "    img = Image.fromarray(img)\n",
    "    basewidth =299\n",
    "    wpercent = (basewidth / float(img.size[0]))\n",
    "    hsize = int((float(img.size[1]) * float(wpercent)))\n",
    "    img = img.resize((basewidth, hsize), PIL.Image.ANTIALIAS)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs,labels,names = load_training_images('tiny-imagenet-200/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = imgs[0:100]\n",
    "labels = labels[0:100]\n",
    "names = names[0:100]\n",
    "imgs_large = np.ndarray(shape= [imgs.shape[0],299,299,3])\n",
    "for i in range(imgs.shape[0]):\n",
    "    imgs_large[i,:,:,:] = rescale(imgs[i])\n",
    "imgs_large=imgs_large.astype('uint8')\n",
    "imgs_noisy = np.ndarray(shape= imgs_large.shape)\n",
    "for i in range(imgs_large.shape[0]):\n",
    "    imgs_noisy[i,:,:,:] = noisy(1,imgs_large[i])\n",
    "imgs_noisy=imgs_noisy.astype('uint8')\n",
    "sub_imgs,sub_labels = subsample(imgs_noisy,labels)\n",
    "batch_shape = [20, 299, 299, 3]\n",
    "num_classes = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_new_last_layer(base_model, nb_classes):\n",
    "  \"\"\"Add last layer to the convnet\n",
    "  Args:\n",
    "    base_model: keras model excluding top\n",
    "    nb_classes: # of classes\n",
    "  Returns:\n",
    "    new keras model with last layer\n",
    "  \"\"\"\n",
    "  x = base_model.output\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(1024, activation='relu')(x) \n",
    "  predictions = Dense(nb_classes, activation='softmax')(x) \n",
    "  model = Model(input=base_model.input, output=predictions)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_to_finetune(model):\n",
    "   \"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top \n",
    "      layers.\n",
    "   note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in \n",
    "         the inceptionv3 architecture\n",
    "   Args:\n",
    "     model: keras model\n",
    "   \"\"\"\n",
    "   for layer in model.layers:\n",
    "      layer.trainable = True\n",
    "   model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),   \n",
    "                 loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "model = add_new_last_layer(base_model, 201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_to_finetune(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "for type in os.listdir('tiny-imagenet-200/train/'):\n",
    "    all_labels = all_labels+[type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in sub_labels:\n",
    "    ind = all_labels.index(i)\n",
    "    ind_sub = list(sub_labels).index(i)\n",
    "    sub_labels[ind_sub] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_labels = keras.utils.to_categorical(sub_labels, num_classes=201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "80/80 [==============================] - 87s 1s/step - loss: 5.8231\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f2bd41d27431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    sub_imgs,sub_labels,\n",
    "    epochs=1,\n",
    "    batch_size=20\n",
    "    )\n",
    "model.save(args.output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
