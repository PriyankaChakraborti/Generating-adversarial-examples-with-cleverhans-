{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import os\n",
    "import PIL\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from random import randrange\n",
    "%matplotlib inline\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils_tf import model_train, model_eval\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_keras import cnn_model\n",
    "from cleverhans.utils_keras import KerasModelWrapper\n",
    "from cleverhans.attacks import LBFGS\n",
    "from cleverhans.attacks import BasicIterativeMethod\n",
    "from collections import Counter\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from keras.models import load_model\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "#print('x_train shape:', x_train.shape)\n",
    "#print(x_train.shape[0], 'train samples')\n",
    "#print(x_test.shape[0], 'test samples')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "sess = tf.Session()\n",
    "keras.backend.set_session(sess)\n",
    "def model_arch():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "#model = model_arch()\n",
    "#model.fit(x_train, y_train,\n",
    "#          batch_size=batch_size,\n",
    "#          epochs=epochs,\n",
    "#          verbose=1)\n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "#score[1]\n",
    "def subsample(training_images,training_labels, ratio=0.8):\n",
    "    shuffle_index = np.random.permutation(len(training_labels))\n",
    "    training_images = training_images[shuffle_index]\n",
    "    training_labels = training_labels[shuffle_index]\n",
    "    sample = list()\n",
    "    sample_labels = list()\n",
    "    n_sample = round(training_images.shape[0] * ratio)\n",
    "    while len(sample) < n_sample:\n",
    "        index = randrange(training_images.shape[0])\n",
    "        sample.append(training_images[index,:,:,:])\n",
    "        sample_labels.append(training_labels[index])\n",
    "    return np.asarray(sample),np.asarray(sample_labels)\n",
    "def add_gaussian_noise(X_train, mean, stddev):\n",
    "    ''' \n",
    "    INPUT:  (1) 4D numpy array: all raw training image data, of shape \n",
    "                (#imgs, #chan, #rows, #cols)\n",
    "            (2) float: the mean of the Gaussian to sample noise from\n",
    "            (3) float: the standard deviation of the Gaussian to sample\n",
    "                noise from. Note that the range of pixel values is\n",
    "                0-255; choose the standard deviation appropriately. \n",
    "    OUTPUT: (1) 4D numpy array: noisy training data, of shape\n",
    "                (#imgs, #chan, #rows, #cols)\n",
    "    '''\n",
    "    n_imgs = X_train.shape[0]\n",
    "    n_chan = X_train.shape[3]\n",
    "    n_rows = X_train.shape[1]\n",
    "    n_cols = X_train.shape[2]\n",
    "    if stddev == 0:\n",
    "        noise = np.zeros((n_imgs, n_rows, n_cols,n_chan))\n",
    "    else:\n",
    "        noise = np.random.normal(mean, stddev/255., \n",
    "                                 (n_imgs,n_rows, n_cols,n_chan))\n",
    "    noisy_X = X_train + noise\n",
    "    clipped_noisy_X = np.clip(noisy_X, 0., 1.)\n",
    "    return clipped_noisy_X\n",
    "def fgsm_attack(train_data,model,sess):\n",
    "    wrap = KerasModelWrapper(model)\n",
    "    fgsm = FastGradientMethod(wrap, sess=sess)\n",
    "    fgsm_params = {'eps': 0.3,\n",
    "                   'clip_min': 0.,\n",
    "                   'clip_max': 1.}\n",
    "    adv_x = fgsm.generate_np(train_data, **fgsm_params)\n",
    "    return adv_x\n",
    "def bim_attack(train_data,model,sess):\n",
    "    wrap = KerasModelWrapper(model)\n",
    "    bim = BasicIterativeMethod(wrap, sess=sess)\n",
    "    bim_params = {'eps_iter': 0.01,\n",
    "              'nb_iter': 10,\n",
    "              'clip_min': 0.,\n",
    "              'clip_max': 1.}\n",
    "    adv_x = bim.generate_np(train_data, **bim_params)\n",
    "    return adv_x\n",
    "def lbfgs_attack(train_data,model,sess,tar_class):\n",
    "    wrap = KerasModelWrapper(model)\n",
    "    lbfgs = LBFGS(wrap,sess=sess)\n",
    "    one_hot_target = np.zeros((train_data.shape[0], 10), dtype=np.float32)\n",
    "    one_hot_target[:, tar_class] = 1\n",
    "    adv = lbfgs.generate_np(train_data, max_iterations=10,\n",
    "                                        binary_search_steps=3,\n",
    "                                        initial_const=1,\n",
    "                                        clip_min=-5, clip_max=5,\n",
    "                                        batch_size=1, y_target=one_hot_target)\n",
    "    return adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_ens=10\n",
    "#Add gaussian noise to all images\n",
    "x_noisy = add_gaussian_noise(x_train,0,64)\n",
    "#variable to store the predictions of each model in the ensemble (10)\n",
    "preds_ens = np.zeros((x_test.shape[0],10))\n",
    "#variable to store Majority vote from all models in ensemble\n",
    "max_vote_ens = np.zeros(x_test.shape[0])\n",
    "for i in range(n_ens):\n",
    "    #Build a new model architecture for every model in the ensemble\n",
    "    model = model_arch()\n",
    "    #subsample from the entire data, bagging\n",
    "    sub_imgs,sub_labels = subsample(x_noisy,y_train)\n",
    "    #train the model\n",
    "    model.fit(sub_imgs, sub_labels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)\n",
    "    #save the model\n",
    "    model.save(\"/Users/venkatakrishnamohansunkara/Desktop/csce 896/project/Model\"+i+\".h5\")\n",
    "    #get the predictions of the model\n",
    "    ans = sess.run(tf.argmax(model.predict(x_test),axis=1))\n",
    "    #store the predictions of this particular model(i) in ith column of pred_ens variable\n",
    "    preds_ens[:,i]= ans.reshape((x_test.shape[0],1))\n",
    "    #erase the model\n",
    "    del model\n",
    "#Now the variable pred_ens consists of the predictions of all test_data for each model in ensemble.\n",
    "#ith column contains predictions of ith model.\n",
    "#go through every row\n",
    "for i in range(preds_ens.shape[0]):\n",
    "    #get the entire row which consists of predictions for that particular instance from all models.\n",
    "    b= Counter(preds_ens[i])\n",
    "    #get the maximum vote i.e which number has more frequency.\n",
    "    max_vote_ens[i] = b.most_common(1)[0][0]\n",
    "#accuracy of ensemble\n",
    "ens_acc = sess.run(tf.reduce_mean(tf.cast(tf.equal(max_vote_ens, tf.argmax(y_test, axis=1)) , tf.float32)))\n",
    "#Build a model for normal training on the entire noisy data.\n",
    "model = model_arch()\n",
    "model.fit(x_noisy, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)\n",
    "acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "#accuracy of normal model on noisy train data\n",
    "acc_noisy_normal = acc[1]\n",
    "del model\n",
    "#Build a new model for normal training (without ensemble) on entire train data (with out bagging and noise).\n",
    "model = model_arch()\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)\n",
    "acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "model.save(\"/Users/venkatakrishnamohansunkara/Desktop/csce 896/project/original_Model.h5\")\n",
    "#accuracy of normal model\n",
    "acc_normal = acc[1]\n",
    "#generate fgsm adversarial examples on test_data\n",
    "adv_fgsm = fgsm_attack(x_test,model,sess)\n",
    "acc_fgsm = model.evaluate(adv_fgsm, y_test, verbose=0)\n",
    "#accuracy of normal model on fgsm adversarial examples\n",
    "acc_fgsm = acc_fgsm[1]\n",
    "#generate bim adversarial examples on test_data\n",
    "adv_bim = bim_attack(x_test,model,sess)\n",
    "acc_bim = model.evaluate(adv_bim,y_test,verbose=0)\n",
    "#accuracy of normal model on bim adversarial examples\n",
    "acc_bim = acc_bim[1]\n",
    "#generate lbfgs adversarial examples on test_data\n",
    "# The target is chosen as 6\n",
    "adv_lbfgs = lbfgs_attack(x_test,model,sess,6)\n",
    "acc_lbfgs = model.evaluate(adv_lbfgs,y_test,verbose=0)\n",
    "#accuracy of normal model on lbfgs adversarial examples\n",
    "acc_lbfgs = acc_lbfgs[1]\n",
    "#variable to store the predictions of each model in the ensemble (10) for fgsm adversarial examples\n",
    "preds_ens_fgsm = np.zeros((x_test.shape[0],10))\n",
    "#variable to store Majority vote from all models in ensemble for fgsm adversarial examples\n",
    "max_vote_ens_fgsm = np.zeros(x_test.shape[0])\n",
    "#variable to store the predictions of each model in the ensemble (10) for bim adversarial examples\n",
    "preds_ens_bim = np.zeros((x_test.shape[0],10))\n",
    "#variable to store Majority vote from all models in ensemble for bim adversarial examples\n",
    "max_vote_ens_bim = np.zeros(x_test.shape[0])\n",
    "#variable to store the predictions of each model in the ensemble (10) for lbfgs adversarial examples\n",
    "preds_ens_lbfgs = np.zeros((x_test.shape[0],10))\n",
    "#variable to store Majority vote from all models in ensemble for lbfgs adversarial examples\n",
    "max_vote_ens_lbfgs = np.zeros(x_test.shape[0])\n",
    "for i in range(10):\n",
    "    model = load_model(model.save(\"/Users/venkatakrishnamohansunkara/Desktop/csce 896/project/Model\"+i+\".h5\"))\n",
    "    #get predictions of model i for fgsm adversarial examples\n",
    "    ans = sess.run(tf.argmax(model.predict(adv_fgsm),axis=1))\n",
    "    preds_ens_fgsm[:,i]= ans.reshape((adv_fgsm.shape[0],1))\n",
    "    #get predictions of model i for bim adversarial examples\n",
    "    ans = sess.run(tf.argmax(model.predict(adv_bim),axis=1))\n",
    "    preds_ens_bim[:,i]= ans.reshape((adv_bim.shape[0],1))\n",
    "    #get predictions of model i for lbfgs adversarial examples\n",
    "    ans = sess.run(tf.argmax(model.predict(adv_lbfgs),axis=1))\n",
    "    preds_ens_lbfgs[:,i]= ans.reshape((adv_lbfgs.shape[0],1))\n",
    "    del model\n",
    "#Now the variable pred_ens consists of the predictions of all fgsm adversarial test_data for each model in ensemble.\n",
    "#ith column contains predictions of ith model.\n",
    "#go through every row\n",
    "for i in range(preds_ens_fgsm.shape[0]):\n",
    "    b= Counter(preds_ens_fgsm[i])\n",
    "    max_vote_ens_fgsm[i] = b.most_common(1)[0][0]\n",
    "#accuracy of ensemble on fgsm_adv\n",
    "ens_acc_fgsm = sess.run(tf.reduce_mean(tf.cast(tf.equal(max_vote_ens_fgsm, tf.argmax(y_test, axis=1)) , tf.float32)))\n",
    "#Now the variable pred_ens consists of the predictions of all bim adversarial test_data for each model in ensemble.\n",
    "#ith column contains predictions of ith model.\n",
    "#go through every row\n",
    "for i in range(preds_ens_bim.shape[0]):\n",
    "    b= Counter(preds_ens_bim[i])\n",
    "    max_vote_ens_bim[i] = b.most_common(1)[0][0]\n",
    "#accuracy of ensemble on bim_adv\n",
    "ens_acc_bim = sess.run(tf.reduce_mean(tf.cast(tf.equal(max_vote_ens_bim, tf.argmax(y_test, axis=1)) , tf.float32)))\n",
    "#Now the variable pred_ens consists of the predictions of all lbfgs adversarial test_data for each model in ensemble.\n",
    "#ith column contains predictions of ith model.\n",
    "#go through every row\n",
    "for i in range(preds_ens_lbfgs.shape[0]):\n",
    "    b= Counter(preds_ens_lbfgs[i])\n",
    "    max_vote_ens_lbfgs[i] = b.most_common(1)[0][0]\n",
    "#accuracy of ensemble on lbfgs_adv\n",
    "ens_acc_lbfgs = sess.run(tf.reduce_mean(tf.cast(tf.equal(max_vote_ens_lbfgs, tf.argmax(y_test, axis=1)) , tf.float32)))\n",
    "#\n",
    "#-----------------------------------Adversarial Training--------------------------------------------------------------\n",
    "#first adversarial examples are generated using train_data, then the model is trained on train_data+adv_train_data.\n",
    "#Then the model is tested on normal test_data, then the model is tested on adversarial_test_data.\n",
    "#So, we are generating the adversarial examples twice both on train and test data.\n",
    "model = load_model(model.save(\"/Users/venkatakrishnamohansunkara/Desktop/csce 896/project/original_Model.h5\"))\n",
    "wrap = KerasModelWrapper(model)\n",
    "#generate adversarial examples on train data.\n",
    "adv_fgsm_train = fgsm_attack(x_train,model,sess)\n",
    "adv_bim_train = bim_attack(x_train,model,sess)\n",
    "adv_lbfgs_train = lbfgs_attack(x_train,model,sess)\n",
    "train_plus_adv_fgsm = np.concatenate([x_train,adv_fgsm_train])\n",
    "y_train_plus_adv_fgsm = np.concatenate([y_train,y_train])\n",
    "train_plus_adv_bim = np.concatenate([x_train,adv_bim_train])\n",
    "y_train_plus_adv_bim = np.concatenate([y_train,y_train])\n",
    "train_plus_adv_lbfgs = np.concatenate([x_train,adv_lbfgs_train])\n",
    "y_train_plus_adv_lbfgs = np.concatenate([y_train,y_train])\n",
    "del model\n",
    "#build a fresh model for fgsm training\n",
    "model = model_arch()\n",
    "wrap = KerasModelWrapper(model)\n",
    "model.fit(train_plus_adv_fgsm, y_train_plus_adv_fgsm,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)\n",
    "fgsm_acc_train = model.evaluate(x_test,y_test,verbose=0)\n",
    "#Accuracy of adversarially trained model on clean examples\n",
    "fgsm_acc_train[1]\n",
    "#generate adversarial examples for adversarially trained model on test_data\n",
    "adv_fgsm_test = fgsm_attack(x_test,model,sess,6)\n",
    "fgsm_adv_acc_train = model.evaluate(adv_fgsm_test,y_test,verbose=0)\n",
    "#Accuracy of adversarially trained model on adv_test images\n",
    "fgsm_adv_acc_train[1]\n",
    "del model\n",
    "#build a fresh model for bim training\n",
    "model = model_arch()\n",
    "wrap = KerasModelWrapper(model)\n",
    "model.fit(train_plus_adv_bim, y_train_plus_adv_bim,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)\n",
    "bim_acc_train = model.evaluate(x_test,y_test,verbose=0)\n",
    "#Accuracy of adversarially trained model on clean examples\n",
    "bim_acc_train[1]\n",
    "#generate adversarial examples for adversarially trained model on test_data\n",
    "adv_bim_test = bim_attack(x_test,model,sess,6)\n",
    "bim_adv_acc_train = model.evaluate(adv_bim_test,y_test,verbose=0)\n",
    "#Accuracy of adversarially trained model on adv_test images\n",
    "bim_adv_acc_train[1]\n",
    "del model\n",
    "#build a fresh model for lbfgs training\n",
    "model = model_arch()\n",
    "wrap = KerasModelWrapper(model)\n",
    "model.fit(train_plus_adv_lbfgs, y_train_plus_adv_lbfgs,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1)\n",
    "lbfgs_acc_train = model.evaluate(x_test,y_test,verbose=0)\n",
    "#Accuracy of adversarially trained model on clean examples\n",
    "lbfgs_acc_train[1]\n",
    "adv_lbfgs_test = lbfgs_attack(x_test,model,sess,6)\n",
    "lbfgs_adv_acc_train = model.evaluate(adv_lbfgs_test,y_test,verbose=0)\n",
    "#Accuracy of adversarially trained model on adv_test images\n",
    "lbfgs_adv_acc_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
